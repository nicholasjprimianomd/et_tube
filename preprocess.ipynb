{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\nprim\\Downloads\\ranzcr-clip-catheter-line-classification\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['ETT - Abnormal'] == '1') | (df['ETT - Borderline'] == 1)| (df['ETT - Normal'] == 1)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = r'F:\\ET_Tube\\RANZCR_ET_Tubes'\n",
    "source_dir = r'C:\\Users\\nprim\\Downloads\\ranzcr-clip-catheter-line-classification\\train'\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for UID in tqdm(filtered_df[\"StudyInstanceUID\"]):\n",
    "    dest_path = os.path.join(dest_dir, UID  + \".jpg\")\n",
    "    input_image = os.path.join(source_dir, UID  + \".jpg\")\n",
    "    image = Image.open(input_image)\n",
    "    image.save(dest_path)\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(UID, source_dir, dest_dir):\n",
    "    dest_path = os.path.join(dest_dir, UID + \".jpg\")\n",
    "    input_image = os.path.join(source_dir, UID + \".jpg\")\n",
    "    image = Image.open(input_image)\n",
    "    image.save(dest_path)\n",
    "    image.close()\n",
    "\n",
    "source_dir =  r'C:\\Users\\nprim\\Downloads\\ranzcr-clip-catheter-line-classification\\train'\n",
    "dest_dir = r'F:\\ET_Tube\\RANZCR_ET_Tubes'\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "num_threads = 8\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Create a list of tasks\n",
    "    tasks = [executor.submit(process_image, UID, source_dir, dest_dir) for UID in filtered_df[\"StudyInstanceUID\"]]\n",
    "    \n",
    "    # Use tqdm to display progress\n",
    "    for _ in tqdm(concurrent.futures.as_completed(tasks), total=len(tasks)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import concurrent.futures\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adjust_image(input_path, output_path, brightness_factor, contrast_factor):\n",
    "    # Open the image\n",
    "    image = Image.open(input_path)\n",
    "\n",
    "    # Adjust brightness\n",
    "    #enhancer = ImageEnhance.Brightness(image)\n",
    "    #image = enhancer.enhance(brightness_factor)\n",
    "\n",
    "    # Adjust contrast\n",
    "    #enhancer = ImageEnhance.Contrast(image)\n",
    "    #image = enhancer.enhance(contrast_factor)\n",
    "\n",
    "\n",
    "    image = np.array(image)\n",
    "    image = exposure.equalize_adapthist(image/np.max(image))\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # Save the adjusted image\n",
    "    image.save(output_path)\n",
    "    image.close()\n",
    "\n",
    "source_dir = r'F:\\ET_Tube\\RANZCR_ET_Tubes'\n",
    "dest_dir = r'F:\\ET_Tube\\RANZCR_ET_Tubes\\Adjusted'\n",
    "\n",
    "brightness_factor = 1 # Decrease brightness (set a value between 0 and 1)\n",
    "contrast_factor = 1  # Increase contrast (set a value greater than 1)\n",
    "\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "num_threads = 8\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Create a list of tasks\n",
    "    tasks = []\n",
    "    count = 0\n",
    "    for filename in os.listdir(source_dir):\n",
    "        count=count+1\n",
    "        if filename.endswith('.jpg'):  \n",
    "            input_path = os.path.join(source_dir, filename)\n",
    "            output_path = os.path.join(dest_dir, filename)\n",
    "            task = executor.submit(adjust_image, input_path, output_path, brightness_factor, contrast_factor)\n",
    "            tasks.append(task)\n",
    "        if count == 2:\n",
    "            break\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"filtered_df = df[(df['AP/PA'] == 'AP') & (df['Support Devices'] == 1.0)]\n",
    "jpg_filepaths = filtered_df[\"Path\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir_me = 'F:\\ET_Tube\\CheXpert-v1.0\\support_devices_only_ap_me'\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = len(jpg_filepaths) //2\n",
    "nick_jpg = jpg_filepaths[:middle]\n",
    "nate_jps = jpg_filepaths[middle:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, filepath in tqdm(enumerate(nick_jpg)):\n",
    "    dest_path = os.path.join(dest_dir, str(idx))\n",
    "    input_image = os.path.join(current_directory, filepath)\n",
    "    image = Image.open(input_image)\n",
    "    image.save(dest_path+\".jpg\")\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = 'F:\\ET_Tube\\CheXpert-v1.0\\support_devices_only_ap'\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, filepath in tqdm(enumerate(nate_jps)):\n",
    "    dest_path = os.path.join(dest_dir, str(idx))\n",
    "    input_image = os.path.join(current_directory, filepath)\n",
    "    image = Image.open(input_image)\n",
    "    image.save(dest_path+\".jpg\")\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(r\"F:\\ET_Tube\\CheXpert-v1.0\\support_devices_only_ap_me\\0.jpg\")\n",
    "imag = np.array(image)\n",
    "img = exposure.equalize_adapthist(img/np.max(img))\n",
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(img, 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(r\"F:\\ET_Tube\\CheXpert-v1.0\\support_devices_only_ap_me\\0.jpg\")\n",
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(np.array(image), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'F:\\ET_Tube\\RANZCR_ET_Tubes'\n",
    "\n",
    "xrlist = os.listdir(source_dir)\n",
    "\n",
    "dest_dir = r'F:\\ET_Tube\\RANZCR_ET_Tubes\\Adjusted'\n",
    "\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "for filepath in tqdm(xrlist):\n",
    "\n",
    "    \n",
    "    input_image = os.path.join(source_dir, filepath)\n",
    "    image = Image.open(input_image)\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = exposure.equalize_adapthist(image/np.max(image))\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.convert('L')\n",
    "    output_image = os.path.join(dest_dir, filepath)\n",
    "    image.save(output_image, \"JPEG\")\n",
    "    \n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(r\"F:\\ET_Tube\\RANZCR_ET_Tubes\\1.2.826.0.1.3680043.8.498.10001645884963994872672157437761279872.jpg\")\n",
    "image = np.array(image)\n",
    "#image = exposure.equalize_adapthist(image/np.max(image))\n",
    "image = Image.fromarray(image)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(np.array(image), 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(image)\n",
    "#image = image.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import keras\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from keras import optimizers\n",
    "from numpy import array \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile,join\n",
    "import glob\n",
    "import cv2\n",
    "from skimage import feature \n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = r'F:\\ET_Tube\\RANZCR_ET_Tubes'\n",
    "imgs = os.listdir(path_1)\n",
    "paths_list = [path_1]\n",
    "\n",
    "dstpath =  r'F:\\ET_Tube\\RANZCR_ET_Tubes\\Adjusted'\n",
    "\n",
    "for imgnm in tqdm(imgs):\n",
    "    images = plt.imread(os.path.join(path_1, imgnm))\n",
    "    #gray_image = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(9, (10, 10))\n",
    "    normalized = clahe.apply(images)\n",
    "    \n",
    "for path in tqdm(paths_list):\n",
    "    \n",
    "    files = [f for f in listdir(path) if isfile(join(path,f))]\n",
    "    \n",
    "for image in tqdm(files):\n",
    "    try:   \n",
    "        dstPath = join(dstpath, image)\n",
    "        cv2.imwrite(dstPath, normalized)\n",
    "    \n",
    "    except:\n",
    "        print (\"{} is not converted\".format(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(r'F:\\ET_Tube\\RANZCR_ET_Tubes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5245/8381 [05:00<02:47, 18.72it/s]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import   join\n",
    "from tqdm import tqdm\n",
    "\n",
    "dstpath =  r'F:\\ET_Tube\\RANZCR_ET_Tubes\\Adjusted'\n",
    "\n",
    "for img in tqdm(listdir(r'F:\\ET_Tube\\RANZCR_ET_Tubes')):\n",
    "    src = cv2.imread(join(r'F:\\ET_Tube\\RANZCR_ET_Tubes', img))\n",
    "    clahe = cv2.createCLAHE(3, (4, 4))\n",
    "    gray_image = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    normalized = clahe.apply(gray_image)\n",
    "    cv2.imwrite(join(dstpath, img), normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
